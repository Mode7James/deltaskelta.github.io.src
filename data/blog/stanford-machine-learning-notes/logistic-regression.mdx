---
title: Logistic Regression
published: true
createdAt: 2019-02-15T12:38:13.957Z
updatedAt: 2019-07-21T15:02:06.877Z
images:
  - ./sigmoid.svg
categories:
  - Programming
  - Algorithms
  - Machine Learning
  - Stanford
---

## Logistic Regression

<props.imgs.Img1 align="left" width="40%" />

Linear regression is good for predicting values that have a linear relationship to the data. In classification
problems, however, there are a limited number of values that are being predicted. Like "Is this a
picture of a dog?", "Is this a spam email?", etc.

The hypothesis function is then given in terms of the likelihood of `x` being classfied as `0` or `1`. The `g(z)`
below is the function that produces the curve in the picture. It is called a sigmoid function.

The sigmoid function takes any `x` value and converts it to somewhere between 0 and 1. An `x` value of `0` gives the otput
`0.5` and a very large value of `x` will give a number very close to 1 and a very small value of `x` will give a number
very close to `0`.

$$
  \begin{aligned}
   &h_\theta(x) = g(\theta^Tx) \\
   &z = \theta^Tx \\
   &g(z) = \frac{1}{1 + e^{-z}}
  \end{aligned}
$$


If we are only choosing from two possibilities, then the following must be true...

$$
h_\theta(x) = P(y = 1 | x;\theta) = 1 - P(y = 0|x;\theta)
$$

## Decision Boundary

From the equations and chart above we can deduce that when $ z = 0 $
then $ g(z) = 1/2 $. So if `z` were to be more than 0, the result would then be greater than `0.5`.
Since $ \theta^Tx $ can be substituted for $ z $ we can then say the following.

$$
 \begin{aligned}
   &g(z) >= 0.5 \quad when \quad z \geq  0 \\
   &h_\theta(x) = g(\theta^Tx) \geq 0.5 \quad whenever \quad \theta^Tx \geq 0 \\
 \end{aligned}
$$

The same is true in the opposite case, whenever $ \theta^Tx $ is less than 0, then `g(z)` will be less
than 0.5.

## The Cost Function and Gradient Descent

For logistic regression, the cost function is also the mean of the sum of all the costs, but instead of the mean of
squared error, it is defined as...

$$
  \begin{aligned}
    J(\theta) &= \frac{1}{m} \sum_{i=1}^m Cost(h_\theta(x^{(i)}), y^{(i)}) \\
    Cost(h_\theta(x), y) &= \begin{cases}
     -log(h_\theta(x)) &\text{if } y = 1 \\
     -log(1 - h_\theta(x)) &\text{if } y = 0
    \end{cases} \\
    Cost(h_\theta(x), y) &= -y * log(h_\theta(x)) - (1 - y)log(1 - h_\theta(x)) \\
    J(\theta) &= \frac{1}{m} (-y^T log(h_\theta(x))) - (1 - y)^T log(1 - h_\theta(x))))
  \end{aligned}
$$

In order to run gradient descent with this cost function we need to take the partial derivative of the cost function and
update each theta simultaneously.

$$
  \begin{aligned}
    \theta_j &:= \theta_j - \alpha \frac{\partial}{\partial \theta_j}J(\theta) \\
    \theta_j &:= \theta_j - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_J^{(i)} \\
    \theta &:= \theta - \frac{\alpha}{m} X^T(g(X\theta) - \overrightarrow{y})
  \end{aligned}
$$
