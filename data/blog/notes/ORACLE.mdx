---
title: ORACLE
published: false
createdAt: 2019-03-26T03:47:48.013Z
updatedAt: 2019-04-21T04:30:34.404Z
categories:
  - Programming
  - Algorithms
  - Machine Learning
  - Neural Networks
---

import { M } from '../../../src/components/math';

## The Problem

- expanding neural networks to learn new tasks.
- past work includes advanced regularizations to prevent drastic changes in existing network weights.
- past work: allowing network to expand its capacity without catastrophic forgetting.
- the remaining problem is that the order of the learned tasks has an effect on the performance after learning all
  tasks.
- curriculum learning (gradually increasing the task difficulty) could solve the problem, but it is untenable in real
  world situations.
- existing methods are order sensitive because new adjustments to the model parameters affects performance on previously
  learned tasks.

## Proposed Solution

- split parameters into task shared and task specific parameters.
- task shared parameters should stay relatively static
- when training for a new task, task adaptive parameters for earlier tasks, are only updated to reflect changes in the
  task shared parameters
- new tasks will be biased to learn more from the task specific parameters
- task shared parameters should sometimes be updated, when this happens task specific parameters should also be updated
  to reflect these changes in task shared parameters.
- matrix decomposition (factorization) is used to split the parameters into task shared and task specific parameters.
- to prevent excessive increases in network capacity, task specific parameters are factorized into sparse low rank
  matrices (sparse = majority 0 value, low-rank = low number of column vectors)
- result: order-robust, efficient, outperforms other methods with fewer parameters.

## Problem Setting

- <M i="D_t"/> - dataset of the `t`th task.
- <M i="\lbrace x_t^i, y^i_t \rbrace_{i=1}^{N_t}" /> - x is the i<sup>th</sup> training example of the
  t<sup>th</sup> dataset, and y is its label. N is the number of examples in for task t
- <M i="\Theta_t = {\theta^l_t}" /> - a set of weights for the task t and layer l.
- <M i="\theta_t = \sigma + \tau_t" /> - sigma is the task shared parameter, and tau is the task adaptive
  parameter.
- <M i="\odot" /> - hadamard product (elementwise multiplication)
- <M i="\otimes" /> - tensor product  (what???)
- <M i="|| \sigma ||" />  - magnitude of the vector <M i="sqrt(sum(sigma .* sigma))" />
- <M i="|| \sigma ||_p = (\sum_{i=1}^n |x_i|^p)^{1/p}" />.
- <M i="\sigma^{(t - 1)} = U \Sigma V^T" /> which is the single value decomposition `svd()` function
- <M i="\tau_t = P_t Q_t" /> where <M i="P_t = U \Sigma^{1/2}" /> and <M i="Q_t = V \Sigma^{1/2}" />
- `l2` regularizer - AKA "ridge regression" <M i="\lambda \sum_{j=1}^P \theta_j^2" /> - same as <M i="|| \theta ||_2^2"/>
- `l1` regulizer - AKA "lasso refression" <M i="\lambda \sum_{j=1}^P | \theta_j |" /> - same as <M i="|| \theta ||_1 " />.
- first learn the task adaptive parameters, then update the task shared parameters

- The initial task theta values are are learned for the first task. This means that the shared parameters and the task
  specific parameters are learned since <M i="\theta_t = \sigma + \tau_t" />.
- The shared parameter <M i="\sigma^{(t - 1)}" /> in the algorithm is shared by every level, so it doesn't
  need to be recovered for every level.
- The P and Q values need to be stored at every iteration of the learning algorithm
- The <M i="\theta" /> values at each task should remain the samer. Since the theta values are
  constructed from the shared params, task-params, and masks, and the shared parameters are "relatively" static,
  then most of the changes are happening in the task specific parameters.

## Questions:

- When is this method useful? (on things where most knowledge is learned up front? most on the backend?)
- How to minimize the P and Q matrices
